âœ‹ Plains Indian Sign Language Hand Gesture Detection

> ðŸ§  Hybrid ML Model + ðŸŽ¥ Real-Time Hand Gesture Detection Software  
> [Masters of Applied Computing] | [Wilfrid Laurier University]  
> Completed: April 2025

---

## ðŸš€ Overview

This project demonstrates a **complete pipeline for recognizing hand gestures in Plains Indian Sign Language (PISL)** using a **hybrid deep learning model** with real-time inference capability.

The project covers:

- ðŸ“¦ **Preprocessing dataset** â†’ Extract frames + hand landmarks  
- ðŸ§  **Hybrid Model Training** â†’ CNN + Hand Landmarks â†’ `Hybrid_hand_model.h5`  
- ðŸŽ® **Real-time Prediction Software** â†’ Live gesture detection via webcam  
- ðŸ“’ **Jupyter Notebook** â†’ Full walkthrough & reproducibility

A video demonstration is available under `Software/Demonstration.mp4`.

---

## ðŸ“ Project Structure

â”œâ”€â”€ Model/
â”‚ â”œâ”€â”€ Preprocessing & Landmark Scripts
â”‚ â”œâ”€â”€ Hybrid_hand_model.h5
â”‚ â”œâ”€â”€ Processed Dataset (Shortcut)
â”‚
â”œâ”€â”€ Software/
â”‚ â”œâ”€â”€ realtime_prediction.py
â”‚ â”œâ”€â”€ datasets/
â”‚ â”œâ”€â”€ preprocessed_dataset/
â”‚ â”œâ”€â”€ landmarks/
â”‚ â”œâ”€â”€ Demonstration.mp4
â”‚
â”œâ”€â”€ Notebook/
â”‚ â”œâ”€â”€ Plains_HandSign_Detection.ipynb
â”‚ â”œâ”€â”€ processed_dataset/
â”‚
â””â”€â”€ README.md

## ðŸ§° Technologies Used

- Python 3.x
- MediaPipe â†’ Real-time hand tracking
- OpenCV â†’ Frame extraction + real-time video processing
- TensorFlow / Keras â†’ Hybrid ML model
- NumPy, Pandas â†’ Data preprocessing
- Jupyter Notebook â†’ Project walkthrough

---

## ðŸ§  Hybrid Model

Combines:
- ðŸ“· **CNN layers** â†’ RGB, Grayscale, Binary frames  
- âœ‹ **Landmark vectors** â†’ 21 point hand keypoints  
- ðŸ”— **Fully Connected Layers (MLP)** â†’ Final gesture classification

> **Achieved ~96% accuracy on validation set.**

---

## ðŸŽ® Real-Time Gesture Prediction

`realtime_prediction.py` runs gesture detection live:

- Uses webcam feed
- Detects hand landmarks via MediaPipe
- Passes frame + landmarks to hybrid model
- Displays live predictions + bounding boxes

âœ… Easy to run â†’ All datasets + model included in `/Software`  
âœ… Pre-trained model â†’ No need to retrain

---

## ðŸ“’ Notebook for Training & Review

Notebook (`Notebook/Plains_HandSign_Detection.ipynb`) shows:

- Dataset loading and preprocessing
- Landmark extraction
- Model architecture
- Training and evaluation
- Final model exportyou can find a .ipynb file and the other relevant folders in the same. In the python notebook file, the executed process will be available for viewing and reviewing our project.

Run Command
cd Software
python realtime_prediction.py
